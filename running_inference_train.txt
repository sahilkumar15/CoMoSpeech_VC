cd model\monotonic_align
mkedir -p model\monotonic_align
cd ..\..

python setup.py build_ext --inplace


python inference.py -f .\resources\filelists\synthesis.txt -c .\checkpts\model_0.pt -t 100

CoMoSpeech_VC\logs\20230826_student\model_0.pt

python inference.py -f .\resources\filelists\synthesis2.txt -c .\logs\20230826_student\model_0.pt -t 100

CoMoSpeech_VC\logs\prof_2\model_prof_20000.pt



python inference.py -f .\resources\filelists\synthesis2.txt -c .\logs\prof_2\model_prof_20000.pt -t 100
python inference.py -f .\resources\filelists\synthesis2.txt -c .\logs\harsha_1\model_14000.pt -t 100

D:\Yeshiva\Applications of AI\RA\CoMoSpeech

D:\Yeshiva\Spring24\AI_of_Application\CoMoSpeech_VC

Denoising diffusion probabilistic models (DDPMs) have shown promising performance for speech synthesis. However, a large number of iterative steps are required to achieve high sample quality, which restricts the inference speed. Maintaining sample quality while increasing sampling speed has become a challenging task. In this paper, we propose a Consistency Model-based Speech synthesis method, CoMoSpeech, which achieve speech synthesis through a single diffusion sampling step while achieving high audio quality. The consistency constraint is applied to distill a consistency model from a well-designed diffusion-based teacher model, which ultimately yields superior performances in the distilled CoMoSpeech. Our experiments show that by generating audio recordings by a single sampling step, the CoMoSpeech achieves an inference speed more than 150 times faster than real-time on a single NVIDIA A100 GPU, which is comparable to FastSpeech2, making diffusion-sampling based speech synthesis truly practical. Meanwhile, objective and subjective evaluations on text-to-speech and singing voice synthesis show that the proposed teacher models yield the best audio quality, and the one-step sampling based CoMoSpeech achieves the best inference speed with better or comparable audio quality to other conventional multi-step diffusion model baselines.


(como) D:\Yeshiva\Applications of AI\RA\CoMoSpeech>python train.py
Traceback (most recent call last):
  File "D:\Yeshiva\Applications of AI\RA\CoMoSpeech\train.py", line 15, in <module>
    from data import TextMelDataset, TextMelBatchCollate
  File "D:\Yeshiva\Applications of AI\RA\CoMoSpeech\data.py", line 15, in <module>
    from meldataset import mel_spectrogram
  File "D:\Yeshiva\Applications of AI\RA\CoMoSpeech\hifi-gan\meldataset.py", line 9, in <module>
    from librosa.util import normalize
  File "C:\Users\msnam\anaconda3\envs\como\lib\site-packages\librosa\__init__.py", line 211, in <module>
    from . import core
  File "C:\Users\msnam\anaconda3\envs\como\lib\site-packages\librosa\core\__init__.py", line 9, in <module>
    from .constantq import *  # pylint: disable=wildcard-import
  File "C:\Users\msnam\anaconda3\envs\como\lib\site-packages\librosa\core\constantq.py", line 1058, in <module>
    dtype=np.complex,
  File "C:\Users\msnam\anaconda3\envs\como\lib\site-packages\numpy\__init__.py", line 338, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'complex'.
`np.complex` was a deprecated alias for the builtin `complex`. To avoid this error in existing code, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'complex_'?